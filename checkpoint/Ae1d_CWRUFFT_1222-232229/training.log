12-22 23:22:29 model_name: Ae1d
12-22 23:22:29 data_name: CWRUFFT
12-22 23:22:29 data_dir: C:\Users\Tracy_Lucia\Desktop\CWRU
12-22 23:22:29 normlizetype: 0-1
12-22 23:22:29 processing_type: R_A
12-22 23:22:29 cuda_device: 0
12-22 23:22:29 checkpoint_dir: ./checkpoint
12-22 23:22:29 pretrained: True
12-22 23:22:29 batch_size: 32
12-22 23:22:29 num_workers: 0
12-22 23:22:29 opt: adam
12-22 23:22:29 lr: 0.001
12-22 23:22:29 momentum: 0.9
12-22 23:22:29 weight_decay: 1e-05
12-22 23:22:29 lr_scheduler: fix
12-22 23:22:29 gamma: 0.1
12-22 23:22:29 steps: 10,20,30,40
12-22 23:22:29 steps1: 50,80
12-22 23:22:29 middle_epoch: 50
12-22 23:22:29 max_epoch: 100
12-22 23:22:29 print_step: 100
12-22 23:22:29 using 1 cpu
12-22 23:22:30 -----Epoch 0/49-----
12-22 23:22:30 current lr: 0.001
12-22 23:22:30 Epoch: 0 [0/1044], Train Loss: 0.1856552.7 examples/sec 0.06 sec/batch
12-22 23:22:31 Epoch: 0 train-Loss: 0.0386, Cost 1.4106 sec
12-22 23:22:31 Epoch: 0 val-Loss: 0.0125, Cost 0.0416 sec
12-22 23:22:31 -----Epoch 1/49-----
12-22 23:22:31 current lr: 0.001
12-22 23:22:33 Epoch: 1 train-Loss: 0.0140, Cost 1.4294 sec
12-22 23:22:33 Epoch: 1 val-Loss: 0.0121, Cost 0.0360 sec
12-22 23:22:33 -----Epoch 2/49-----
12-22 23:22:33 current lr: 0.001
12-22 23:22:34 Epoch: 2 train-Loss: 0.0136, Cost 1.3950 sec
12-22 23:22:34 Epoch: 2 val-Loss: 0.0128, Cost 0.0360 sec
12-22 23:22:34 -----Epoch 3/49-----
12-22 23:22:34 current lr: 0.001
12-22 23:22:34 Epoch: 3 [32/1044], Train Loss: 0.0203722.6 examples/sec 0.04 sec/batch
12-22 23:22:35 Epoch: 3 train-Loss: 0.0136, Cost 1.4027 sec
12-22 23:22:35 Epoch: 3 val-Loss: 0.0119, Cost 0.0362 sec
12-22 23:22:35 -----Epoch 4/49-----
12-22 23:22:35 current lr: 0.001
12-22 23:22:37 Epoch: 4 train-Loss: 0.0142, Cost 1.3946 sec
12-22 23:22:37 Epoch: 4 val-Loss: 0.0120, Cost 0.0392 sec
12-22 23:22:37 -----Epoch 5/49-----
12-22 23:22:37 current lr: 0.001
12-22 23:22:38 Epoch: 5 train-Loss: 0.0134, Cost 1.4095 sec
12-22 23:22:38 Epoch: 5 val-Loss: 0.0117, Cost 0.0439 sec
12-22 23:22:38 -----Epoch 6/49-----
12-22 23:22:38 current lr: 0.001
12-22 23:22:38 Epoch: 6 [64/1044], Train Loss: 0.0137724.1 examples/sec 0.04 sec/batch
12-22 23:22:40 Epoch: 6 train-Loss: 0.0134, Cost 1.4210 sec
12-22 23:22:40 Epoch: 6 val-Loss: 0.0120, Cost 0.0370 sec
12-22 23:22:40 -----Epoch 7/49-----
12-22 23:22:40 current lr: 0.001
12-22 23:22:41 Epoch: 7 train-Loss: 0.0133, Cost 1.3960 sec
12-22 23:22:41 Epoch: 7 val-Loss: 0.0118, Cost 0.0366 sec
12-22 23:22:41 -----Epoch 8/49-----
12-22 23:22:41 current lr: 0.001
12-22 23:22:43 Epoch: 8 train-Loss: 0.0131, Cost 1.4214 sec
12-22 23:22:43 Epoch: 8 val-Loss: 0.0122, Cost 0.0374 sec
12-22 23:22:43 -----Epoch 9/49-----
12-22 23:22:43 current lr: 0.001
12-22 23:22:43 Epoch: 9 [96/1044], Train Loss: 0.0132721.7 examples/sec 0.04 sec/batch
12-22 23:22:44 Epoch: 9 train-Loss: 0.0132, Cost 1.4517 sec
12-22 23:22:44 Epoch: 9 val-Loss: 0.0118, Cost 0.0429 sec
12-22 23:22:44 -----Epoch 10/49-----
12-22 23:22:44 current lr: 0.001
12-22 23:22:46 Epoch: 10 train-Loss: 0.0132, Cost 1.5252 sec
12-22 23:22:46 Epoch: 10 val-Loss: 0.0118, Cost 0.0493 sec
12-22 23:22:46 -----Epoch 11/49-----
12-22 23:22:46 current lr: 0.001
12-22 23:22:47 Epoch: 11 train-Loss: 0.0131, Cost 1.5613 sec
12-22 23:22:47 Epoch: 11 val-Loss: 0.0117, Cost 0.0360 sec
12-22 23:22:47 -----Epoch 12/49-----
12-22 23:22:47 current lr: 0.001
12-22 23:22:48 Epoch: 12 [128/1044], Train Loss: 0.0132667.6 examples/sec 0.05 sec/batch
12-22 23:22:49 Epoch: 12 train-Loss: 0.0130, Cost 1.4904 sec
12-22 23:22:49 Epoch: 12 val-Loss: 0.0115, Cost 0.0363 sec
12-22 23:22:49 -----Epoch 13/49-----
12-22 23:22:49 current lr: 0.001
12-22 23:22:50 Epoch: 13 train-Loss: 0.0130, Cost 1.4425 sec
12-22 23:22:50 Epoch: 13 val-Loss: 0.0120, Cost 0.0419 sec
12-22 23:22:50 -----Epoch 14/49-----
12-22 23:22:50 current lr: 0.001
12-22 23:22:55 Epoch: 14 train-Loss: 0.0130, Cost 5.0702 sec
12-22 23:22:56 Epoch: 14 val-Loss: 0.0118, Cost 0.1722 sec
12-22 23:22:56 -----Epoch 15/49-----
12-22 23:22:56 current lr: 0.001
12-22 23:22:57 Epoch: 15 [160/1044], Train Loss: 0.0130349.8 examples/sec 0.09 sec/batch
12-22 23:23:01 Epoch: 15 train-Loss: 0.0130, Cost 5.3755 sec
12-22 23:23:01 Epoch: 15 val-Loss: 0.0115, Cost 0.1331 sec
12-22 23:23:01 -----Epoch 16/49-----
12-22 23:23:01 current lr: 0.001
12-22 23:23:06 Epoch: 16 train-Loss: 0.0130, Cost 5.1489 sec
12-22 23:23:06 Epoch: 16 val-Loss: 0.0115, Cost 0.1419 sec
12-22 23:23:06 -----Epoch 17/49-----
12-22 23:23:06 current lr: 0.001
12-22 23:23:12 Epoch: 17 train-Loss: 0.0130, Cost 5.4970 sec
12-22 23:23:12 Epoch: 17 val-Loss: 0.0127, Cost 0.1748 sec
12-22 23:23:12 -----Epoch 18/49-----
12-22 23:23:12 current lr: 0.001
12-22 23:23:13 Epoch: 18 [192/1044], Train Loss: 0.0130189.5 examples/sec 0.17 sec/batch
12-22 23:23:18 Epoch: 18 train-Loss: 0.0129, Cost 5.9040 sec
12-22 23:23:18 Epoch: 18 val-Loss: 0.0126, Cost 0.1824 sec
12-22 23:23:18 -----Epoch 19/49-----
12-22 23:23:18 current lr: 0.001
12-22 23:23:24 Epoch: 19 train-Loss: 0.0129, Cost 5.7948 sec
12-22 23:23:24 Epoch: 19 val-Loss: 0.0120, Cost 0.1518 sec
12-22 23:23:24 -----Epoch 20/49-----
12-22 23:23:24 current lr: 0.001
12-22 23:23:30 Epoch: 20 train-Loss: 0.0130, Cost 5.8882 sec
12-22 23:23:30 Epoch: 20 val-Loss: 0.0114, Cost 0.1640 sec
12-22 23:23:30 -----Epoch 21/49-----
12-22 23:23:30 current lr: 0.001
12-22 23:23:32 Epoch: 21 [224/1044], Train Loss: 0.0129172.9 examples/sec 0.18 sec/batch
12-22 23:23:36 Epoch: 21 train-Loss: 0.0128, Cost 5.7443 sec
12-22 23:23:36 Epoch: 21 val-Loss: 0.0114, Cost 0.1477 sec
12-22 23:23:36 -----Epoch 22/49-----
12-22 23:23:36 current lr: 0.001
12-22 23:23:42 Epoch: 22 train-Loss: 0.0128, Cost 5.5744 sec
12-22 23:23:42 Epoch: 22 val-Loss: 0.0115, Cost 0.1656 sec
12-22 23:23:42 -----Epoch 23/49-----
12-22 23:23:42 current lr: 0.001
12-22 23:23:47 Epoch: 23 train-Loss: 0.0128, Cost 5.6038 sec
12-22 23:23:48 Epoch: 23 val-Loss: 0.0113, Cost 0.1834 sec
12-22 23:23:48 -----Epoch 24/49-----
12-22 23:23:48 current lr: 0.001
12-22 23:23:49 Epoch: 24 [256/1044], Train Loss: 0.0128179.8 examples/sec 0.18 sec/batch
12-22 23:23:53 Epoch: 24 train-Loss: 0.0128, Cost 5.8464 sec
12-22 23:23:54 Epoch: 24 val-Loss: 0.0114, Cost 0.1382 sec
12-22 23:23:54 -----Epoch 25/49-----
12-22 23:23:54 current lr: 0.001
12-22 23:23:59 Epoch: 25 train-Loss: 0.0127, Cost 5.5607 sec
12-22 23:23:59 Epoch: 25 val-Loss: 0.0114, Cost 0.1520 sec
12-22 23:23:59 -----Epoch 26/49-----
12-22 23:23:59 current lr: 0.001
12-22 23:24:05 Epoch: 26 train-Loss: 0.0129, Cost 5.7815 sec
12-22 23:24:05 Epoch: 26 val-Loss: 0.0114, Cost 0.1427 sec
12-22 23:24:05 -----Epoch 27/49-----
12-22 23:24:05 current lr: 0.001
12-22 23:24:07 Epoch: 27 [288/1044], Train Loss: 0.0127178.3 examples/sec 0.18 sec/batch
12-22 23:24:11 Epoch: 27 train-Loss: 0.0130, Cost 5.6992 sec
12-22 23:24:11 Epoch: 27 val-Loss: 0.0113, Cost 0.1696 sec
12-22 23:24:11 -----Epoch 28/49-----
12-22 23:24:11 current lr: 0.001
12-22 23:24:17 Epoch: 28 train-Loss: 0.0128, Cost 5.7920 sec
12-22 23:24:17 Epoch: 28 val-Loss: 0.0112, Cost 0.1733 sec
12-22 23:24:17 -----Epoch 29/49-----
12-22 23:24:17 current lr: 0.001
12-22 23:24:22 Epoch: 29 train-Loss: 0.0128, Cost 5.3687 sec
12-22 23:24:23 Epoch: 29 val-Loss: 0.0116, Cost 0.1604 sec
12-22 23:24:23 -----Epoch 30/49-----
12-22 23:24:23 current lr: 0.001
12-22 23:24:24 Epoch: 30 [320/1044], Train Loss: 0.0129181.5 examples/sec 0.17 sec/batch
12-22 23:24:28 Epoch: 30 train-Loss: 0.0129, Cost 5.6587 sec
12-22 23:24:28 Epoch: 30 val-Loss: 0.0208, Cost 0.1658 sec
12-22 23:24:28 -----Epoch 31/49-----
12-22 23:24:28 current lr: 0.001
12-22 23:24:34 Epoch: 31 train-Loss: 0.0129, Cost 5.3207 sec
12-22 23:24:34 Epoch: 31 val-Loss: 0.0128, Cost 0.1603 sec
12-22 23:24:34 -----Epoch 32/49-----
12-22 23:24:34 current lr: 0.001
12-22 23:24:39 Epoch: 32 train-Loss: 0.0127, Cost 5.2926 sec
12-22 23:24:39 Epoch: 32 val-Loss: 0.0118, Cost 0.1504 sec
12-22 23:24:39 -----Epoch 33/49-----
12-22 23:24:39 current lr: 0.001
12-22 23:24:41 Epoch: 33 [352/1044], Train Loss: 0.0128187.9 examples/sec 0.17 sec/batch
12-22 23:24:45 Epoch: 33 train-Loss: 0.0127, Cost 5.3303 sec
12-22 23:24:45 Epoch: 33 val-Loss: 0.0112, Cost 0.1851 sec
12-22 23:24:45 -----Epoch 34/49-----
12-22 23:24:45 current lr: 0.001
12-22 23:24:50 Epoch: 34 train-Loss: 0.0126, Cost 5.1789 sec
12-22 23:24:50 Epoch: 34 val-Loss: 0.0115, Cost 0.1716 sec
12-22 23:24:50 -----Epoch 35/49-----
12-22 23:24:50 current lr: 0.001
12-22 23:24:55 Epoch: 35 train-Loss: 0.0128, Cost 5.1800 sec
12-22 23:24:56 Epoch: 35 val-Loss: 0.0115, Cost 0.1881 sec
12-22 23:24:56 -----Epoch 36/49-----
12-22 23:24:56 current lr: 0.001
12-22 23:24:58 Epoch: 36 [384/1044], Train Loss: 0.0127192.2 examples/sec 0.16 sec/batch
12-22 23:25:01 Epoch: 36 train-Loss: 0.0128, Cost 5.3068 sec
12-22 23:25:01 Epoch: 36 val-Loss: 0.0118, Cost 0.1424 sec
12-22 23:25:01 -----Epoch 37/49-----
12-22 23:25:01 current lr: 0.001
12-22 23:25:06 Epoch: 37 train-Loss: 0.0127, Cost 5.2376 sec
12-22 23:25:06 Epoch: 37 val-Loss: 0.0116, Cost 0.1430 sec
12-22 23:25:06 -----Epoch 38/49-----
12-22 23:25:06 current lr: 0.001
12-22 23:25:12 Epoch: 38 train-Loss: 0.0128, Cost 5.3805 sec
12-22 23:25:12 Epoch: 38 val-Loss: 0.0118, Cost 0.1651 sec
12-22 23:25:12 -----Epoch 39/49-----
12-22 23:25:12 current lr: 0.001
12-22 23:25:14 Epoch: 39 [416/1044], Train Loss: 0.0127191.5 examples/sec 0.17 sec/batch
12-22 23:25:17 Epoch: 39 train-Loss: 0.0127, Cost 5.1693 sec
12-22 23:25:17 Epoch: 39 val-Loss: 0.0112, Cost 0.1428 sec
12-22 23:25:17 -----Epoch 40/49-----
12-22 23:25:17 current lr: 0.001
12-22 23:25:21 Epoch: 40 train-Loss: 0.0126, Cost 4.0982 sec
12-22 23:25:21 Epoch: 40 val-Loss: 0.0115, Cost 0.0356 sec
12-22 23:25:21 -----Epoch 41/49-----
12-22 23:25:21 current lr: 0.001
12-22 23:25:23 Epoch: 41 train-Loss: 0.0126, Cost 1.2969 sec
12-22 23:25:23 Epoch: 41 val-Loss: 0.0114, Cost 0.0396 sec
12-22 23:25:23 -----Epoch 42/49-----
12-22 23:25:23 current lr: 0.001
12-22 23:25:23 Epoch: 42 [448/1044], Train Loss: 0.0127347.9 examples/sec 0.09 sec/batch
12-22 23:25:24 Epoch: 42 train-Loss: 0.0127, Cost 1.3134 sec
12-22 23:25:24 Epoch: 42 val-Loss: 0.0122, Cost 0.0356 sec
12-22 23:25:24 -----Epoch 43/49-----
12-22 23:25:24 current lr: 0.001
12-22 23:25:25 Epoch: 43 train-Loss: 0.0128, Cost 1.2642 sec
12-22 23:25:25 Epoch: 43 val-Loss: 0.0113, Cost 0.0330 sec
12-22 23:25:25 -----Epoch 44/49-----
12-22 23:25:25 current lr: 0.001
12-22 23:25:27 Epoch: 44 train-Loss: 0.0126, Cost 1.2436 sec
12-22 23:25:27 Epoch: 44 val-Loss: 0.0113, Cost 0.0340 sec
12-22 23:25:27 -----Epoch 45/49-----
12-22 23:25:27 current lr: 0.001
12-22 23:25:27 Epoch: 45 [480/1044], Train Loss: 0.0127799.4 examples/sec 0.04 sec/batch
12-22 23:25:28 Epoch: 45 train-Loss: 0.0127, Cost 1.2393 sec
12-22 23:25:28 Epoch: 45 val-Loss: 0.0113, Cost 0.0409 sec
12-22 23:25:28 -----Epoch 46/49-----
12-22 23:25:28 current lr: 0.001
12-22 23:25:29 Epoch: 46 train-Loss: 0.0126, Cost 1.2318 sec
12-22 23:25:29 Epoch: 46 val-Loss: 0.0112, Cost 0.0385 sec
12-22 23:25:29 -----Epoch 47/49-----
12-22 23:25:29 current lr: 0.001
12-22 23:25:30 Epoch: 47 train-Loss: 0.0126, Cost 1.2274 sec
12-22 23:25:30 Epoch: 47 val-Loss: 0.0112, Cost 0.0337 sec
12-22 23:25:30 -----Epoch 48/49-----
12-22 23:25:30 current lr: 0.001
12-22 23:25:31 Epoch: 48 [512/1044], Train Loss: 0.0126826.8 examples/sec 0.04 sec/batch
12-22 23:25:32 Epoch: 48 train-Loss: 0.0125, Cost 1.3761 sec
12-22 23:25:32 Epoch: 48 val-Loss: 0.0112, Cost 0.0507 sec
12-22 23:25:32 -----Epoch 49/49-----
12-22 23:25:32 current lr: 0.001
12-22 23:25:35 Epoch: 49 train-Loss: 0.0127, Cost 3.4305 sec
12-22 23:25:35 Epoch: 49 val-Loss: 0.0136, Cost 0.1573 sec
12-22 23:25:35 -----Epoch 0/99-----
12-22 23:25:35 current lr: 0.001
12-22 23:25:38 Epoch: 0 train-Loss: 1.8371 train-Acc: 0.5364, Cost 2.9364 sec
12-22 23:25:39 Epoch: 0 val-Loss: 1.2583 val-Acc: 0.7586, Cost 0.1040 sec
12-22 23:25:39 save best model epoch 0, acc 0.7586
12-22 23:25:39 -----Epoch 1/99-----
12-22 23:25:39 current lr: 0.001
12-22 23:25:40 Epoch: 1 [544/1044], Train Loss: 0.8437 Train Acc: 0.3012,349.8 examples/sec 0.09 sec/batch
12-22 23:25:41 Epoch: 1 train-Loss: 1.1780 train-Acc: 0.7040, Cost 2.8968 sec
12-22 23:25:42 Epoch: 1 val-Loss: 0.5060 val-Acc: 0.9923, Cost 0.1101 sec
12-22 23:25:42 save best model epoch 1, acc 0.9923
12-22 23:25:42 -----Epoch 2/99-----
12-22 23:25:42 current lr: 0.001
12-22 23:25:45 Epoch: 2 train-Loss: 0.6878 train-Acc: 0.8487, Cost 2.9885 sec
12-22 23:25:45 Epoch: 2 val-Loss: 0.1710 val-Acc: 1.0000, Cost 0.0972 sec
12-22 23:25:45 save best model epoch 2, acc 1.0000
12-22 23:25:45 -----Epoch 3/99-----
12-22 23:25:45 current lr: 0.001
12-22 23:25:48 Epoch: 3 train-Loss: 0.4528 train-Acc: 0.8707, Cost 3.0033 sec
12-22 23:25:48 Epoch: 3 val-Loss: 0.0678 val-Acc: 1.0000, Cost 0.0887 sec
12-22 23:25:48 -----Epoch 4/99-----
12-22 23:25:48 current lr: 0.001
12-22 23:25:49 Epoch: 4 [576/1044], Train Loss: 0.6306 Train Acc: 0.8391,340.7 examples/sec 0.09 sec/batch
12-22 23:25:51 Epoch: 4 train-Loss: 0.4565 train-Acc: 0.8707, Cost 2.9275 sec
12-22 23:25:51 Epoch: 4 val-Loss: 0.0939 val-Acc: 0.9923, Cost 0.1042 sec
12-22 23:25:51 -----Epoch 5/99-----
12-22 23:25:51 current lr: 0.001
12-22 23:25:54 Epoch: 5 train-Loss: 0.3482 train-Acc: 0.8946, Cost 2.9500 sec
12-22 23:25:54 Epoch: 5 val-Loss: 0.0469 val-Acc: 0.9962, Cost 0.1007 sec
12-22 23:25:54 -----Epoch 6/99-----
12-22 23:25:54 current lr: 0.001
12-22 23:25:57 Epoch: 6 train-Loss: 0.2955 train-Acc: 0.9205, Cost 2.9296 sec
12-22 23:25:57 Epoch: 6 val-Loss: 0.0346 val-Acc: 1.0000, Cost 0.1074 sec
12-22 23:25:57 -----Epoch 7/99-----
12-22 23:25:57 current lr: 0.001
12-22 23:25:59 Epoch: 7 [608/1044], Train Loss: 0.3162 Train Acc: 0.9083,343.3 examples/sec 0.09 sec/batch
12-22 23:26:00 Epoch: 7 train-Loss: 0.2808 train-Acc: 0.9109, Cost 2.9109 sec
12-22 23:26:00 Epoch: 7 val-Loss: 0.0597 val-Acc: 0.9885, Cost 0.0889 sec
12-22 23:26:00 -----Epoch 8/99-----
12-22 23:26:00 current lr: 0.001
12-22 23:26:03 Epoch: 8 train-Loss: 0.2967 train-Acc: 0.9090, Cost 2.8487 sec
12-22 23:26:03 Epoch: 8 val-Loss: 0.0236 val-Acc: 0.9962, Cost 0.0977 sec
12-22 23:26:03 -----Epoch 9/99-----
12-22 23:26:03 current lr: 0.001
12-22 23:26:06 Epoch: 9 train-Loss: 0.2176 train-Acc: 0.9291, Cost 2.8568 sec
12-22 23:26:06 Epoch: 9 val-Loss: 0.0163 val-Acc: 1.0000, Cost 0.0996 sec
12-22 23:26:06 -----Epoch 10/99-----
12-22 23:26:06 current lr: 0.001
12-22 23:26:08 Epoch: 10 [640/1044], Train Loss: 0.2492 Train Acc: 0.9216,351.5 examples/sec 0.09 sec/batch
12-22 23:26:09 Epoch: 10 train-Loss: 0.1835 train-Acc: 0.9435, Cost 2.9320 sec
12-22 23:26:09 Epoch: 10 val-Loss: 0.0193 val-Acc: 1.0000, Cost 0.1035 sec
12-22 23:26:09 -----Epoch 11/99-----
12-22 23:26:09 current lr: 0.001
12-22 23:26:12 Epoch: 11 train-Loss: 0.1921 train-Acc: 0.9435, Cost 2.7671 sec
12-22 23:26:12 Epoch: 11 val-Loss: 0.0125 val-Acc: 1.0000, Cost 0.0887 sec
12-22 23:26:12 -----Epoch 12/99-----
12-22 23:26:12 current lr: 0.001
12-22 23:26:14 Epoch: 12 train-Loss: 0.2085 train-Acc: 0.9301, Cost 2.8390 sec
12-22 23:26:15 Epoch: 12 val-Loss: 0.0256 val-Acc: 0.9923, Cost 0.0941 sec
12-22 23:26:15 -----Epoch 13/99-----
12-22 23:26:15 current lr: 0.001
12-22 23:26:17 Epoch: 13 [672/1044], Train Loss: 0.2005 Train Acc: 0.9381,354.3 examples/sec 0.09 sec/batch
12-22 23:26:18 Epoch: 13 train-Loss: 0.1753 train-Acc: 0.9444, Cost 2.9289 sec
12-22 23:26:18 Epoch: 13 val-Loss: 0.0151 val-Acc: 0.9962, Cost 0.0964 sec
12-22 23:26:18 -----Epoch 14/99-----
12-22 23:26:18 current lr: 0.001
12-22 23:26:20 Epoch: 14 train-Loss: 0.2178 train-Acc: 0.9349, Cost 2.7415 sec
12-22 23:26:20 Epoch: 14 val-Loss: 0.0183 val-Acc: 1.0000, Cost 0.0954 sec
12-22 23:26:20 -----Epoch 15/99-----
12-22 23:26:20 current lr: 0.001
12-22 23:26:23 Epoch: 15 train-Loss: 0.1267 train-Acc: 0.9626, Cost 2.7082 sec
12-22 23:26:23 Epoch: 15 val-Loss: 0.0118 val-Acc: 1.0000, Cost 0.0948 sec
12-22 23:26:23 -----Epoch 16/99-----
12-22 23:26:23 current lr: 0.001
12-22 23:26:25 Epoch: 16 [704/1044], Train Loss: 0.1529 Train Acc: 0.9523,367.2 examples/sec 0.09 sec/batch
12-22 23:26:26 Epoch: 16 train-Loss: 0.1316 train-Acc: 0.9579, Cost 2.7721 sec
12-22 23:26:26 Epoch: 16 val-Loss: 0.0128 val-Acc: 0.9962, Cost 0.1005 sec
12-22 23:26:26 -----Epoch 17/99-----
12-22 23:26:26 current lr: 0.001
12-22 23:26:29 Epoch: 17 train-Loss: 0.2024 train-Acc: 0.9454, Cost 2.9612 sec
12-22 23:26:29 Epoch: 17 val-Loss: 0.0152 val-Acc: 1.0000, Cost 0.0922 sec
12-22 23:26:29 -----Epoch 18/99-----
12-22 23:26:29 current lr: 0.001
12-22 23:26:32 Epoch: 18 train-Loss: 0.1585 train-Acc: 0.9483, Cost 2.9587 sec
12-22 23:26:32 Epoch: 18 val-Loss: 0.0097 val-Acc: 1.0000, Cost 0.0877 sec
12-22 23:26:32 -----Epoch 19/99-----
12-22 23:26:32 current lr: 0.001
12-22 23:26:34 Epoch: 19 [736/1044], Train Loss: 0.1670 Train Acc: 0.9520,342.5 examples/sec 0.09 sec/batch
12-22 23:26:35 Epoch: 19 train-Loss: 0.1669 train-Acc: 0.9550, Cost 2.9821 sec
12-22 23:26:35 Epoch: 19 val-Loss: 0.0093 val-Acc: 1.0000, Cost 0.0994 sec
12-22 23:26:35 -----Epoch 20/99-----
12-22 23:26:35 current lr: 0.001
12-22 23:26:38 Epoch: 20 train-Loss: 0.1405 train-Acc: 0.9646, Cost 2.9594 sec
12-22 23:26:38 Epoch: 20 val-Loss: 0.0102 val-Acc: 1.0000, Cost 0.0974 sec
12-22 23:26:38 -----Epoch 21/99-----
12-22 23:26:38 current lr: 0.001
12-22 23:26:41 Epoch: 21 train-Loss: 0.1762 train-Acc: 0.9473, Cost 2.9489 sec
12-22 23:26:41 Epoch: 21 val-Loss: 0.0131 val-Acc: 1.0000, Cost 0.1117 sec
12-22 23:26:41 -----Epoch 22/99-----
12-22 23:26:41 current lr: 0.001
12-22 23:26:44 Epoch: 22 [768/1044], Train Loss: 0.1777 Train Acc: 0.9488,341.4 examples/sec 0.09 sec/batch
12-22 23:26:44 Epoch: 22 train-Loss: 0.1679 train-Acc: 0.9473, Cost 2.9451 sec
12-22 23:26:44 Epoch: 22 val-Loss: 0.0094 val-Acc: 1.0000, Cost 0.1004 sec
12-22 23:26:44 -----Epoch 23/99-----
12-22 23:26:44 current lr: 0.001
12-22 23:26:47 Epoch: 23 train-Loss: 0.1127 train-Acc: 0.9655, Cost 2.9196 sec
12-22 23:26:48 Epoch: 23 val-Loss: 0.0078 val-Acc: 1.0000, Cost 0.1065 sec
12-22 23:26:48 -----Epoch 24/99-----
12-22 23:26:48 current lr: 0.001
12-22 23:26:50 Epoch: 24 train-Loss: 0.1695 train-Acc: 0.9511, Cost 2.8968 sec
12-22 23:26:51 Epoch: 24 val-Loss: 0.0065 val-Acc: 1.0000, Cost 0.1089 sec
12-22 23:26:51 -----Epoch 25/99-----
12-22 23:26:51 current lr: 0.001
12-22 23:26:53 Epoch: 25 [800/1044], Train Loss: 0.1403 Train Acc: 0.9580,345.7 examples/sec 0.09 sec/batch
12-22 23:26:53 Epoch: 25 train-Loss: 0.1797 train-Acc: 0.9511, Cost 2.8992 sec
12-22 23:26:54 Epoch: 25 val-Loss: 0.0056 val-Acc: 1.0000, Cost 0.0924 sec
12-22 23:26:54 -----Epoch 26/99-----
12-22 23:26:54 current lr: 0.001
12-22 23:26:56 Epoch: 26 train-Loss: 0.1218 train-Acc: 0.9540, Cost 2.9278 sec
12-22 23:26:57 Epoch: 26 val-Loss: 0.0088 val-Acc: 1.0000, Cost 0.1102 sec
12-22 23:26:57 -----Epoch 27/99-----
12-22 23:26:57 current lr: 0.001
12-22 23:26:59 Epoch: 27 train-Loss: 0.1215 train-Acc: 0.9626, Cost 2.9242 sec
12-22 23:27:00 Epoch: 27 val-Loss: 0.0058 val-Acc: 1.0000, Cost 0.0949 sec
12-22 23:27:00 -----Epoch 28/99-----
12-22 23:27:00 current lr: 0.001
12-22 23:27:02 Epoch: 28 [832/1044], Train Loss: 0.1279 Train Acc: 0.9611,358.7 examples/sec 0.09 sec/batch
12-22 23:27:02 Epoch: 28 train-Loss: 0.1191 train-Acc: 0.9665, Cost 2.2108 sec
12-22 23:27:02 Epoch: 28 val-Loss: 0.0062 val-Acc: 1.0000, Cost 0.0200 sec
12-22 23:27:02 -----Epoch 29/99-----
12-22 23:27:02 current lr: 0.001
12-22 23:27:04 Epoch: 29 train-Loss: 0.1367 train-Acc: 0.9579, Cost 1.8459 sec
12-22 23:27:04 Epoch: 29 val-Loss: 0.0095 val-Acc: 1.0000, Cost 0.1087 sec
12-22 23:27:04 -----Epoch 30/99-----
12-22 23:27:04 current lr: 0.001
12-22 23:27:06 Epoch: 30 train-Loss: 0.1830 train-Acc: 0.9483, Cost 2.2471 sec
12-22 23:27:06 Epoch: 30 val-Loss: 0.0086 val-Acc: 1.0000, Cost 0.0902 sec
12-22 23:27:06 -----Epoch 31/99-----
12-22 23:27:06 current lr: 0.001
12-22 23:27:09 Epoch: 31 [864/1044], Train Loss: 0.1629 Train Acc: 0.9532,449.1 examples/sec 0.07 sec/batch
12-22 23:27:09 Epoch: 31 train-Loss: 0.1625 train-Acc: 0.9531, Cost 3.0634 sec
12-22 23:27:09 Epoch: 31 val-Loss: 0.0098 val-Acc: 1.0000, Cost 0.1068 sec
12-22 23:27:09 -----Epoch 32/99-----
12-22 23:27:09 current lr: 0.001
12-22 23:27:12 Epoch: 32 train-Loss: 0.1369 train-Acc: 0.9588, Cost 3.1164 sec
12-22 23:27:12 Epoch: 32 val-Loss: 0.0066 val-Acc: 1.0000, Cost 0.1072 sec
12-22 23:27:12 -----Epoch 33/99-----
12-22 23:27:12 current lr: 0.001
12-22 23:27:16 Epoch: 33 train-Loss: 0.0875 train-Acc: 0.9693, Cost 3.1540 sec
12-22 23:27:16 Epoch: 33 val-Loss: 0.0055 val-Acc: 1.0000, Cost 0.1063 sec
12-22 23:27:16 -----Epoch 34/99-----
12-22 23:27:16 current lr: 0.001
12-22 23:27:18 Epoch: 34 [896/1044], Train Loss: 0.1031 Train Acc: 0.9665,326.1 examples/sec 0.10 sec/batch
12-22 23:27:19 Epoch: 34 train-Loss: 0.0830 train-Acc: 0.9741, Cost 3.0136 sec
12-22 23:27:19 Epoch: 34 val-Loss: 0.0077 val-Acc: 1.0000, Cost 0.1080 sec
12-22 23:27:19 -----Epoch 35/99-----
12-22 23:27:19 current lr: 0.001
12-22 23:27:22 Epoch: 35 train-Loss: 0.1026 train-Acc: 0.9674, Cost 2.8910 sec
12-22 23:27:22 Epoch: 35 val-Loss: 0.0040 val-Acc: 1.0000, Cost 0.0779 sec
12-22 23:27:22 -----Epoch 36/99-----
12-22 23:27:22 current lr: 0.001
12-22 23:27:25 Epoch: 36 train-Loss: 0.0712 train-Acc: 0.9818, Cost 2.7117 sec
12-22 23:27:25 Epoch: 36 val-Loss: 0.0029 val-Acc: 1.0000, Cost 0.1051 sec
12-22 23:27:25 -----Epoch 37/99-----
12-22 23:27:25 current lr: 0.001
12-22 23:27:27 Epoch: 37 [928/1044], Train Loss: 0.0955 Train Acc: 0.9697,349.3 examples/sec 0.09 sec/batch
12-22 23:27:28 Epoch: 37 train-Loss: 0.1117 train-Acc: 0.9607, Cost 3.0614 sec
12-22 23:27:28 Epoch: 37 val-Loss: 0.0047 val-Acc: 1.0000, Cost 0.1254 sec
12-22 23:27:28 -----Epoch 38/99-----
12-22 23:27:28 current lr: 0.001
12-22 23:27:31 Epoch: 38 train-Loss: 0.0881 train-Acc: 0.9722, Cost 3.3105 sec
12-22 23:27:31 Epoch: 38 val-Loss: 0.0044 val-Acc: 1.0000, Cost 0.1062 sec
12-22 23:27:31 -----Epoch 39/99-----
12-22 23:27:31 current lr: 0.001
12-22 23:27:34 Epoch: 39 train-Loss: 0.0702 train-Acc: 0.9780, Cost 3.2167 sec
12-22 23:27:35 Epoch: 39 val-Loss: 0.0040 val-Acc: 1.0000, Cost 0.1120 sec
12-22 23:27:35 -----Epoch 40/99-----
12-22 23:27:35 current lr: 0.001
12-22 23:27:38 Epoch: 40 [960/1044], Train Loss: 0.0865 Train Acc: 0.9753,309.4 examples/sec 0.10 sec/batch
12-22 23:27:38 Epoch: 40 train-Loss: 0.0962 train-Acc: 0.9770, Cost 3.2543 sec
12-22 23:27:38 Epoch: 40 val-Loss: 0.0035 val-Acc: 1.0000, Cost 0.0998 sec
12-22 23:27:38 -----Epoch 41/99-----
12-22 23:27:38 current lr: 0.001
12-22 23:27:41 Epoch: 41 train-Loss: 0.1025 train-Acc: 0.9693, Cost 2.9743 sec
12-22 23:27:41 Epoch: 41 val-Loss: 0.0083 val-Acc: 1.0000, Cost 0.1103 sec
12-22 23:27:41 -----Epoch 42/99-----
12-22 23:27:41 current lr: 0.001
12-22 23:27:44 Epoch: 42 train-Loss: 0.1121 train-Acc: 0.9655, Cost 3.0924 sec
12-22 23:27:44 Epoch: 42 val-Loss: 0.0050 val-Acc: 1.0000, Cost 0.1095 sec
12-22 23:27:44 -----Epoch 43/99-----
12-22 23:27:44 current lr: 0.001
12-22 23:27:47 Epoch: 43 [992/1044], Train Loss: 0.1036 Train Acc: 0.9684,332.8 examples/sec 0.10 sec/batch
12-22 23:27:47 Epoch: 43 train-Loss: 0.0961 train-Acc: 0.9703, Cost 3.0164 sec
12-22 23:27:47 Epoch: 43 val-Loss: 0.0054 val-Acc: 1.0000, Cost 0.1091 sec
12-22 23:27:47 -----Epoch 44/99-----
12-22 23:27:47 current lr: 0.001
12-22 23:27:50 Epoch: 44 train-Loss: 0.1181 train-Acc: 0.9636, Cost 3.1118 sec
12-22 23:27:51 Epoch: 44 val-Loss: 0.0062 val-Acc: 1.0000, Cost 0.0902 sec
12-22 23:27:51 -----Epoch 45/99-----
12-22 23:27:51 current lr: 0.001
12-22 23:27:53 Epoch: 45 train-Loss: 0.0730 train-Acc: 0.9780, Cost 1.9298 sec
12-22 23:27:53 Epoch: 45 val-Loss: 0.0040 val-Acc: 1.0000, Cost 0.0300 sec
12-22 23:27:53 -----Epoch 46/99-----
12-22 23:27:53 current lr: 0.001
12-22 23:27:55 Epoch: 46 [640/1044], Train Loss: 0.0955 Train Acc: 0.9721,392.6 examples/sec 0.08 sec/batch
12-22 23:27:55 Epoch: 46 train-Loss: 0.0970 train-Acc: 0.9741, Cost 2.6702 sec
12-22 23:27:55 Epoch: 46 val-Loss: 0.0050 val-Acc: 1.0000, Cost 0.0978 sec
12-22 23:27:55 -----Epoch 47/99-----
12-22 23:27:55 current lr: 0.001
12-22 23:27:58 Epoch: 47 train-Loss: 0.0887 train-Acc: 0.9655, Cost 3.1344 sec
12-22 23:27:59 Epoch: 47 val-Loss: 0.0058 val-Acc: 1.0000, Cost 0.0905 sec
12-22 23:27:59 -----Epoch 48/99-----
12-22 23:27:59 current lr: 0.001
12-22 23:28:02 Epoch: 48 train-Loss: 0.1799 train-Acc: 0.9588, Cost 3.1621 sec
12-22 23:28:02 Epoch: 48 val-Loss: 0.0125 val-Acc: 1.0000, Cost 0.1190 sec
12-22 23:28:02 -----Epoch 49/99-----
12-22 23:28:02 current lr: 0.001
12-22 23:28:05 Epoch: 49 train-Loss: 0.1047 train-Acc: 0.9636, Cost 3.3160 sec
12-22 23:28:05 Epoch: 49 val-Loss: 0.0056 val-Acc: 1.0000, Cost 0.1003 sec
12-22 23:28:05 -----Epoch 50/99-----
12-22 23:28:05 current lr: 0.001
12-22 23:28:05 Epoch: 50 [0/1044], Train Loss: 0.1234 Train Acc: 0.9630,311.7 examples/sec 0.10 sec/batch
12-22 23:28:08 Epoch: 50 train-Loss: 0.0946 train-Acc: 0.9693, Cost 3.2271 sec
12-22 23:28:09 Epoch: 50 val-Loss: 0.0040 val-Acc: 1.0000, Cost 0.1103 sec
12-22 23:28:09 -----Epoch 51/99-----
12-22 23:28:09 current lr: 0.001
12-22 23:28:12 Epoch: 51 train-Loss: 0.1064 train-Acc: 0.9732, Cost 3.0878 sec
12-22 23:28:12 Epoch: 51 val-Loss: 0.0058 val-Acc: 1.0000, Cost 0.0967 sec
12-22 23:28:12 -----Epoch 52/99-----
12-22 23:28:12 current lr: 0.001
12-22 23:28:15 Epoch: 52 train-Loss: 0.0714 train-Acc: 0.9799, Cost 3.0124 sec
12-22 23:28:15 Epoch: 52 val-Loss: 0.0088 val-Acc: 0.9962, Cost 0.0987 sec
12-22 23:28:15 -----Epoch 53/99-----
12-22 23:28:15 current lr: 0.001
12-22 23:28:15 Epoch: 53 [32/1044], Train Loss: 0.0908 Train Acc: 0.9738,326.1 examples/sec 0.10 sec/batch
12-22 23:28:18 Epoch: 53 train-Loss: 0.0854 train-Acc: 0.9741, Cost 3.0081 sec
12-22 23:28:18 Epoch: 53 val-Loss: 0.0038 val-Acc: 1.0000, Cost 0.0901 sec
12-22 23:28:18 -----Epoch 54/99-----
12-22 23:28:18 current lr: 0.001
12-22 23:28:21 Epoch: 54 train-Loss: 0.0921 train-Acc: 0.9713, Cost 2.9785 sec
12-22 23:28:21 Epoch: 54 val-Loss: 0.0045 val-Acc: 1.0000, Cost 0.1187 sec
12-22 23:28:21 -----Epoch 55/99-----
12-22 23:28:21 current lr: 0.001
12-22 23:28:24 Epoch: 55 train-Loss: 0.0767 train-Acc: 0.9751, Cost 3.1371 sec
12-22 23:28:24 Epoch: 55 val-Loss: 0.0033 val-Acc: 1.0000, Cost 0.1002 sec
12-22 23:28:24 -----Epoch 56/99-----
12-22 23:28:24 current lr: 0.001
12-22 23:28:25 Epoch: 56 [64/1044], Train Loss: 0.0843 Train Acc: 0.9738,331.2 examples/sec 0.10 sec/batch
12-22 23:28:28 Epoch: 56 train-Loss: 0.0963 train-Acc: 0.9713, Cost 3.3060 sec
12-22 23:28:28 Epoch: 56 val-Loss: 0.0033 val-Acc: 1.0000, Cost 0.1102 sec
12-22 23:28:28 -----Epoch 57/99-----
12-22 23:28:28 current lr: 0.001
12-22 23:28:31 Epoch: 57 train-Loss: 0.0745 train-Acc: 0.9761, Cost 3.3136 sec
12-22 23:28:31 Epoch: 57 val-Loss: 0.0023 val-Acc: 1.0000, Cost 0.1104 sec
12-22 23:28:31 -----Epoch 58/99-----
12-22 23:28:31 current lr: 0.001
12-22 23:28:34 Epoch: 58 train-Loss: 0.0932 train-Acc: 0.9732, Cost 3.2559 sec
12-22 23:28:35 Epoch: 58 val-Loss: 0.0031 val-Acc: 1.0000, Cost 0.1103 sec
12-22 23:28:35 -----Epoch 59/99-----
12-22 23:28:35 current lr: 0.001
12-22 23:28:35 Epoch: 59 [96/1044], Train Loss: 0.0882 Train Acc: 0.9738,306.7 examples/sec 0.10 sec/batch
12-22 23:28:38 Epoch: 59 train-Loss: 0.0641 train-Acc: 0.9808, Cost 3.2992 sec
12-22 23:28:38 Epoch: 59 val-Loss: 0.0042 val-Acc: 1.0000, Cost 0.1002 sec
12-22 23:28:38 -----Epoch 60/99-----
12-22 23:28:38 current lr: 0.001
12-22 23:28:41 Epoch: 60 train-Loss: 0.0646 train-Acc: 0.9799, Cost 3.2557 sec
12-22 23:28:41 Epoch: 60 val-Loss: 0.0022 val-Acc: 1.0000, Cost 0.1001 sec
12-22 23:28:41 -----Epoch 61/99-----
12-22 23:28:41 current lr: 0.001
12-22 23:28:45 Epoch: 61 train-Loss: 0.0896 train-Acc: 0.9761, Cost 3.3276 sec
12-22 23:28:45 Epoch: 61 val-Loss: 0.0034 val-Acc: 1.0000, Cost 0.1101 sec
12-22 23:28:45 -----Epoch 62/99-----
12-22 23:28:45 current lr: 0.001
12-22 23:28:45 Epoch: 62 [128/1044], Train Loss: 0.0778 Train Acc: 0.9772,307.1 examples/sec 0.10 sec/batch
12-22 23:28:48 Epoch: 62 train-Loss: 0.1209 train-Acc: 0.9617, Cost 3.2790 sec
12-22 23:28:48 Epoch: 62 val-Loss: 0.0045 val-Acc: 1.0000, Cost 0.1005 sec
12-22 23:28:48 -----Epoch 63/99-----
12-22 23:28:48 current lr: 0.001
12-22 23:28:51 Epoch: 63 train-Loss: 0.0762 train-Acc: 0.9780, Cost 3.2971 sec
12-22 23:28:52 Epoch: 63 val-Loss: 0.0032 val-Acc: 1.0000, Cost 0.1007 sec
12-22 23:28:52 -----Epoch 64/99-----
12-22 23:28:52 current lr: 0.001
12-22 23:28:55 Epoch: 64 train-Loss: 0.0711 train-Acc: 0.9789, Cost 3.3581 sec
12-22 23:28:55 Epoch: 64 val-Loss: 0.0023 val-Acc: 1.0000, Cost 0.1102 sec
12-22 23:28:55 -----Epoch 65/99-----
12-22 23:28:55 current lr: 0.001
12-22 23:28:56 Epoch: 65 [160/1044], Train Loss: 0.0868 Train Acc: 0.9738,305.5 examples/sec 0.10 sec/batch
12-22 23:28:58 Epoch: 65 train-Loss: 0.0704 train-Acc: 0.9780, Cost 3.3635 sec
12-22 23:28:58 Epoch: 65 val-Loss: 0.0026 val-Acc: 1.0000, Cost 0.1103 sec
12-22 23:28:58 -----Epoch 66/99-----
12-22 23:28:58 current lr: 0.001
12-22 23:29:02 Epoch: 66 train-Loss: 0.0827 train-Acc: 0.9761, Cost 3.3547 sec
12-22 23:29:02 Epoch: 66 val-Loss: 0.0027 val-Acc: 1.0000, Cost 0.0898 sec
12-22 23:29:02 -----Epoch 67/99-----
12-22 23:29:02 current lr: 0.001
12-22 23:29:05 Epoch: 67 train-Loss: 0.0589 train-Acc: 0.9818, Cost 3.2867 sec
12-22 23:29:05 Epoch: 67 val-Loss: 0.0024 val-Acc: 1.0000, Cost 0.1005 sec
12-22 23:29:05 -----Epoch 68/99-----
12-22 23:29:05 current lr: 0.001
12-22 23:29:06 Epoch: 68 [192/1044], Train Loss: 0.0665 Train Acc: 0.9798,304.1 examples/sec 0.10 sec/batch
12-22 23:29:09 Epoch: 68 train-Loss: 0.0460 train-Acc: 0.9847, Cost 3.3945 sec
12-22 23:29:09 Epoch: 68 val-Loss: 0.0029 val-Acc: 1.0000, Cost 0.1204 sec
12-22 23:29:09 -----Epoch 69/99-----
12-22 23:29:09 current lr: 0.001
12-22 23:29:12 Epoch: 69 train-Loss: 0.0734 train-Acc: 0.9770, Cost 3.4176 sec
12-22 23:29:12 Epoch: 69 val-Loss: 0.0022 val-Acc: 1.0000, Cost 0.1103 sec
12-22 23:29:12 -----Epoch 70/99-----
12-22 23:29:12 current lr: 0.001
12-22 23:29:16 Epoch: 70 train-Loss: 0.0686 train-Acc: 0.9789, Cost 3.2009 sec
12-22 23:29:16 Epoch: 70 val-Loss: 0.0024 val-Acc: 1.0000, Cost 0.0902 sec
12-22 23:29:16 -----Epoch 71/99-----
12-22 23:29:16 current lr: 0.001
12-22 23:29:16 Epoch: 71 [224/1044], Train Loss: 0.0600 Train Acc: 0.9814,304.7 examples/sec 0.10 sec/batch
12-22 23:29:19 Epoch: 71 train-Loss: 0.0722 train-Acc: 0.9828, Cost 2.9972 sec
12-22 23:29:19 Epoch: 71 val-Loss: 0.0012 val-Acc: 1.0000, Cost 0.0902 sec
12-22 23:29:19 -----Epoch 72/99-----
12-22 23:29:19 current lr: 0.001
12-22 23:29:22 Epoch: 72 train-Loss: 0.1085 train-Acc: 0.9722, Cost 3.0227 sec
12-22 23:29:22 Epoch: 72 val-Loss: 0.0022 val-Acc: 1.0000, Cost 0.0907 sec
12-22 23:29:22 -----Epoch 73/99-----
12-22 23:29:22 current lr: 0.001
12-22 23:29:25 Epoch: 73 train-Loss: 0.0761 train-Acc: 0.9751, Cost 3.0429 sec
12-22 23:29:25 Epoch: 73 val-Loss: 0.0034 val-Acc: 1.0000, Cost 0.1102 sec
12-22 23:29:25 -----Epoch 74/99-----
12-22 23:29:25 current lr: 0.001
12-22 23:29:26 Epoch: 74 [256/1044], Train Loss: 0.0930 Train Acc: 0.9744,334.9 examples/sec 0.09 sec/batch
12-22 23:29:28 Epoch: 74 train-Loss: 0.0819 train-Acc: 0.9741, Cost 2.9817 sec
12-22 23:29:28 Epoch: 74 val-Loss: 0.0039 val-Acc: 1.0000, Cost 0.1211 sec
12-22 23:29:28 -----Epoch 75/99-----
12-22 23:29:28 current lr: 0.001
12-22 23:29:31 Epoch: 75 train-Loss: 0.0582 train-Acc: 0.9847, Cost 2.9700 sec
12-22 23:29:31 Epoch: 75 val-Loss: 0.0022 val-Acc: 1.0000, Cost 0.1006 sec
12-22 23:29:31 -----Epoch 76/99-----
12-22 23:29:31 current lr: 0.001
12-22 23:29:34 Epoch: 76 train-Loss: 0.0897 train-Acc: 0.9713, Cost 2.9789 sec
12-22 23:29:34 Epoch: 76 val-Loss: 0.0124 val-Acc: 0.9923, Cost 0.1003 sec
12-22 23:29:34 -----Epoch 77/99-----
12-22 23:29:34 current lr: 0.001
12-22 23:29:35 Epoch: 77 [288/1044], Train Loss: 0.0718 Train Acc: 0.9776,337.4 examples/sec 0.09 sec/batch
12-22 23:29:37 Epoch: 77 train-Loss: 0.0487 train-Acc: 0.9837, Cost 3.0489 sec
12-22 23:29:37 Epoch: 77 val-Loss: 0.0017 val-Acc: 1.0000, Cost 0.1057 sec
12-22 23:29:37 -----Epoch 78/99-----
12-22 23:29:37 current lr: 0.001
12-22 23:29:40 Epoch: 78 train-Loss: 0.0901 train-Acc: 0.9732, Cost 2.9621 sec
12-22 23:29:40 Epoch: 78 val-Loss: 0.0020 val-Acc: 1.0000, Cost 0.0902 sec
12-22 23:29:40 -----Epoch 79/99-----
12-22 23:29:40 current lr: 0.001
12-22 23:29:44 Epoch: 79 train-Loss: 0.1016 train-Acc: 0.9732, Cost 3.0683 sec
12-22 23:29:44 Epoch: 79 val-Loss: 0.0239 val-Acc: 1.0000, Cost 0.0998 sec
12-22 23:29:44 -----Epoch 80/99-----
12-22 23:29:44 current lr: 0.001
12-22 23:29:45 Epoch: 80 [320/1044], Train Loss: 0.0859 Train Acc: 0.9763,333.6 examples/sec 0.09 sec/batch
12-22 23:29:47 Epoch: 80 train-Loss: 0.0680 train-Acc: 0.9818, Cost 3.0452 sec
12-22 23:29:47 Epoch: 80 val-Loss: 0.0083 val-Acc: 1.0000, Cost 0.0903 sec
12-22 23:29:47 -----Epoch 81/99-----
12-22 23:29:47 current lr: 0.001
12-22 23:29:50 Epoch: 81 train-Loss: 0.0650 train-Acc: 0.9808, Cost 3.0518 sec
12-22 23:29:50 Epoch: 81 val-Loss: 0.0015 val-Acc: 1.0000, Cost 0.0953 sec
12-22 23:29:50 -----Epoch 82/99-----
12-22 23:29:50 current lr: 0.001
12-22 23:29:53 Epoch: 82 train-Loss: 0.0666 train-Acc: 0.9847, Cost 2.9864 sec
12-22 23:29:53 Epoch: 82 val-Loss: 0.0021 val-Acc: 1.0000, Cost 0.1012 sec
12-22 23:29:53 -----Epoch 83/99-----
12-22 23:29:53 current lr: 0.001
12-22 23:29:54 Epoch: 83 [352/1044], Train Loss: 0.0597 Train Acc: 0.9832,336.9 examples/sec 0.09 sec/batch
12-22 23:29:56 Epoch: 83 train-Loss: 0.0548 train-Acc: 0.9837, Cost 2.9645 sec
12-22 23:29:56 Epoch: 83 val-Loss: 0.0011 val-Acc: 1.0000, Cost 0.0902 sec
12-22 23:29:56 -----Epoch 84/99-----
12-22 23:29:56 current lr: 0.001
12-22 23:29:59 Epoch: 84 train-Loss: 0.0438 train-Acc: 0.9895, Cost 3.0205 sec
12-22 23:29:59 Epoch: 84 val-Loss: 0.0012 val-Acc: 1.0000, Cost 0.1104 sec
12-22 23:29:59 -----Epoch 85/99-----
12-22 23:29:59 current lr: 0.001
12-22 23:30:02 Epoch: 85 train-Loss: 0.0497 train-Acc: 0.9847, Cost 2.9733 sec
12-22 23:30:02 Epoch: 85 val-Loss: 0.0012 val-Acc: 1.0000, Cost 0.1002 sec
12-22 23:30:02 -----Epoch 86/99-----
12-22 23:30:02 current lr: 0.001
12-22 23:30:03 Epoch: 86 [384/1044], Train Loss: 0.0518 Train Acc: 0.9851,337.1 examples/sec 0.09 sec/batch
12-22 23:30:05 Epoch: 86 train-Loss: 0.0617 train-Acc: 0.9789, Cost 2.6883 sec
12-22 23:30:05 Epoch: 86 val-Loss: 0.0016 val-Acc: 1.0000, Cost 0.0799 sec
12-22 23:30:05 -----Epoch 87/99-----
12-22 23:30:05 current lr: 0.001
12-22 23:30:08 Epoch: 87 train-Loss: 0.0620 train-Acc: 0.9818, Cost 2.9380 sec
12-22 23:30:08 Epoch: 87 val-Loss: 0.0014 val-Acc: 1.0000, Cost 0.0903 sec
12-22 23:30:08 -----Epoch 88/99-----
12-22 23:30:08 current lr: 0.001
12-22 23:30:11 Epoch: 88 train-Loss: 0.0803 train-Acc: 0.9751, Cost 3.0193 sec
12-22 23:30:11 Epoch: 88 val-Loss: 0.0030 val-Acc: 1.0000, Cost 0.0903 sec
12-22 23:30:11 -----Epoch 89/99-----
12-22 23:30:11 current lr: 0.001
12-22 23:30:12 Epoch: 89 [416/1044], Train Loss: 0.0661 Train Acc: 0.9791,353.5 examples/sec 0.09 sec/batch
12-22 23:30:14 Epoch: 89 train-Loss: 0.0503 train-Acc: 0.9837, Cost 2.9149 sec
12-22 23:30:14 Epoch: 89 val-Loss: 0.0015 val-Acc: 1.0000, Cost 0.1102 sec
12-22 23:30:14 -----Epoch 90/99-----
12-22 23:30:14 current lr: 0.001
12-22 23:30:17 Epoch: 90 train-Loss: 0.0635 train-Acc: 0.9808, Cost 3.0299 sec
12-22 23:30:17 Epoch: 90 val-Loss: 0.0021 val-Acc: 1.0000, Cost 0.1006 sec
12-22 23:30:17 -----Epoch 91/99-----
12-22 23:30:17 current lr: 0.001
12-22 23:30:20 Epoch: 91 train-Loss: 0.0876 train-Acc: 0.9751, Cost 3.1040 sec
12-22 23:30:21 Epoch: 91 val-Loss: 0.0023 val-Acc: 1.0000, Cost 0.1098 sec
12-22 23:30:21 -----Epoch 92/99-----
12-22 23:30:21 current lr: 0.001
12-22 23:30:22 Epoch: 92 [448/1044], Train Loss: 0.0696 Train Acc: 0.9791,331.5 examples/sec 0.10 sec/batch
12-22 23:30:24 Epoch: 92 train-Loss: 0.0658 train-Acc: 0.9799, Cost 3.0740 sec
12-22 23:30:24 Epoch: 92 val-Loss: 0.0029 val-Acc: 1.0000, Cost 0.1106 sec
12-22 23:30:24 -----Epoch 93/99-----
12-22 23:30:24 current lr: 0.001
12-22 23:30:27 Epoch: 93 train-Loss: 0.0414 train-Acc: 0.9875, Cost 2.9675 sec
12-22 23:30:27 Epoch: 93 val-Loss: 0.0017 val-Acc: 1.0000, Cost 0.1103 sec
12-22 23:30:27 -----Epoch 94/99-----
12-22 23:30:27 current lr: 0.001
12-22 23:30:30 Epoch: 94 train-Loss: 0.0542 train-Acc: 0.9799, Cost 3.1740 sec
12-22 23:30:30 Epoch: 94 val-Loss: 0.0016 val-Acc: 1.0000, Cost 0.1206 sec
12-22 23:30:30 -----Epoch 95/99-----
12-22 23:30:30 current lr: 0.001
12-22 23:30:32 Epoch: 95 [480/1044], Train Loss: 0.0486 Train Acc: 0.9845,325.2 examples/sec 0.10 sec/batch
12-22 23:30:33 Epoch: 95 train-Loss: 0.0481 train-Acc: 0.9866, Cost 3.1123 sec
12-22 23:30:33 Epoch: 95 val-Loss: 0.0018 val-Acc: 1.0000, Cost 0.1003 sec
12-22 23:30:33 -----Epoch 96/99-----
12-22 23:30:33 current lr: 0.001
12-22 23:30:36 Epoch: 96 train-Loss: 0.0386 train-Acc: 0.9866, Cost 3.0298 sec
12-22 23:30:36 Epoch: 96 val-Loss: 0.0017 val-Acc: 1.0000, Cost 0.1104 sec
12-22 23:30:36 -----Epoch 97/99-----
12-22 23:30:36 current lr: 0.001
12-22 23:30:40 Epoch: 97 train-Loss: 0.0898 train-Acc: 0.9789, Cost 3.1035 sec
12-22 23:30:40 Epoch: 97 val-Loss: 0.0026 val-Acc: 1.0000, Cost 0.1210 sec
12-22 23:30:40 -----Epoch 98/99-----
12-22 23:30:40 current lr: 0.001
12-22 23:30:41 Epoch: 98 [512/1044], Train Loss: 0.0674 Train Acc: 0.9814,330.2 examples/sec 0.10 sec/batch
12-22 23:30:43 Epoch: 98 train-Loss: 0.0790 train-Acc: 0.9799, Cost 2.9151 sec
12-22 23:30:43 Epoch: 98 val-Loss: 0.0019 val-Acc: 1.0000, Cost 0.1002 sec
12-22 23:30:43 -----Epoch 99/99-----
12-22 23:30:43 current lr: 0.001
12-22 23:30:46 Epoch: 99 train-Loss: 0.0806 train-Acc: 0.9789, Cost 2.9689 sec
12-22 23:30:46 Epoch: 99 val-Loss: 0.0021 val-Acc: 1.0000, Cost 0.1110 sec
12-22 23:30:46 save best model epoch 99, acc 1.0000
