12-22 20:43:55 model_name: alexnet_1d
12-22 20:43:55 data_name: CWRUFFT
12-22 20:43:55 data_dir: C:\Users\ZAGER\Desktop\DL-based-Intelligent-Diagnosis-Benchmark-master\cwru
12-22 20:43:55 normlizetype: 0-1
12-22 20:43:55 processing_type: R_A
12-22 20:43:55 cuda_device: 0
12-22 20:43:55 checkpoint_dir: ./checkpoint
12-22 20:43:55 pretrained: True
12-22 20:43:55 batch_size: 64
12-22 20:43:55 num_workers: 0
12-22 20:43:55 opt: adam
12-22 20:43:55 lr: 0.001
12-22 20:43:55 momentum: 0.9
12-22 20:43:55 weight_decay: 1e-05
12-22 20:43:55 lr_scheduler: fix
12-22 20:43:55 gamma: 0.1
12-22 20:43:55 steps: 9
12-22 20:43:55 max_epoch: 100
12-22 20:43:55 print_step: 100
12-22 20:43:55 using 1 gpus
12-22 20:43:56 -----Epoch 0/99-----
12-22 20:43:56 current lr: 0.001
12-22 20:43:59 Epoch: 0 [0/1044], Train Loss: 2.3000 Train Acc: 0.1250,23.5 examples/sec 2.72 sec/batch
12-22 20:43:59 Epoch: 0 train-Loss: 2.0976 train-Acc: 0.2098, Cost 2.9689 sec
12-22 20:43:59 Epoch: 0 val-Loss: 1.5241 val-Acc: 0.4521, Cost 0.0330 sec
12-22 20:43:59 save best model epoch 0, acc 0.4521
12-22 20:43:59 -----Epoch 1/99-----
12-22 20:43:59 current lr: 0.001
12-22 20:44:00 Epoch: 1 train-Loss: 1.4612 train-Acc: 0.4540, Cost 0.2777 sec
12-22 20:44:00 Epoch: 1 val-Loss: 1.1184 val-Acc: 0.5900, Cost 0.0320 sec
12-22 20:44:00 save best model epoch 1, acc 0.5900
12-22 20:44:00 -----Epoch 2/99-----
12-22 20:44:00 current lr: 0.001
12-22 20:44:00 Epoch: 2 train-Loss: 1.1359 train-Acc: 0.5900, Cost 0.2607 sec
12-22 20:44:00 Epoch: 2 val-Loss: 0.5821 val-Acc: 0.8123, Cost 0.0340 sec
12-22 20:44:00 save best model epoch 2, acc 0.8123
12-22 20:44:00 -----Epoch 3/99-----
12-22 20:44:00 current lr: 0.001
12-22 20:44:00 Epoch: 3 train-Loss: 0.8875 train-Acc: 0.6772, Cost 0.2687 sec
12-22 20:44:00 Epoch: 3 val-Loss: 0.4339 val-Acc: 0.9157, Cost 0.0420 sec
12-22 20:44:00 save best model epoch 3, acc 0.9157
12-22 20:44:00 -----Epoch 4/99-----
12-22 20:44:00 current lr: 0.001
12-22 20:44:01 Epoch: 4 train-Loss: 0.6585 train-Acc: 0.7605, Cost 0.2637 sec
12-22 20:44:01 Epoch: 4 val-Loss: 0.3288 val-Acc: 0.9004, Cost 0.0340 sec
12-22 20:44:01 -----Epoch 5/99-----
12-22 20:44:01 current lr: 0.001
12-22 20:44:01 Epoch: 5 [960/1044], Train Loss: 1.1169 Train Acc: 0.5901,3365.9 examples/sec 0.02 sec/batch
12-22 20:44:01 Epoch: 5 train-Loss: 0.5250 train-Acc: 0.8247, Cost 0.2747 sec
12-22 20:44:01 Epoch: 5 val-Loss: 0.2399 val-Acc: 0.9425, Cost 0.0360 sec
12-22 20:44:01 save best model epoch 5, acc 0.9425
12-22 20:44:01 -----Epoch 6/99-----
12-22 20:44:01 current lr: 0.001
12-22 20:44:01 Epoch: 6 train-Loss: 0.5040 train-Acc: 0.8439, Cost 0.2657 sec
12-22 20:44:01 Epoch: 6 val-Loss: 0.0907 val-Acc: 0.9847, Cost 0.0330 sec
12-22 20:44:01 save best model epoch 6, acc 0.9847
12-22 20:44:01 -----Epoch 7/99-----
12-22 20:44:01 current lr: 0.001
12-22 20:44:02 Epoch: 7 train-Loss: 0.3627 train-Acc: 0.8841, Cost 0.2627 sec
12-22 20:44:02 Epoch: 7 val-Loss: 0.0796 val-Acc: 0.9885, Cost 0.0350 sec
12-22 20:44:02 save best model epoch 7, acc 0.9885
12-22 20:44:02 -----Epoch 8/99-----
12-22 20:44:02 current lr: 0.001
12-22 20:44:02 Epoch: 8 train-Loss: 0.3069 train-Acc: 0.8966, Cost 0.2807 sec
12-22 20:44:02 Epoch: 8 val-Loss: 0.0970 val-Acc: 0.9808, Cost 0.0350 sec
12-22 20:44:02 -----Epoch 9/99-----
12-22 20:44:02 current lr: 0.001
12-22 20:44:02 Epoch: 9 train-Loss: 0.2839 train-Acc: 0.9090, Cost 0.2707 sec
12-22 20:44:02 Epoch: 9 val-Loss: 0.0355 val-Acc: 0.9847, Cost 0.0330 sec
12-22 20:44:02 -----Epoch 10/99-----
12-22 20:44:02 current lr: 0.001
12-22 20:44:03 Epoch: 10 train-Loss: 0.2541 train-Acc: 0.9291, Cost 0.2687 sec
12-22 20:44:03 Epoch: 10 val-Loss: 0.0320 val-Acc: 0.9962, Cost 0.0330 sec
12-22 20:44:03 save best model epoch 10, acc 0.9962
12-22 20:44:03 -----Epoch 11/99-----
12-22 20:44:03 current lr: 0.001
12-22 20:44:03 Epoch: 11 [832/1044], Train Loss: 0.3331 Train Acc: 0.8934,3286.5 examples/sec 0.02 sec/batch
12-22 20:44:03 Epoch: 11 train-Loss: 0.2737 train-Acc: 0.8985, Cost 0.2737 sec
12-22 20:44:03 Epoch: 11 val-Loss: 0.0417 val-Acc: 0.9885, Cost 0.0340 sec
12-22 20:44:03 -----Epoch 12/99-----
12-22 20:44:03 current lr: 0.001
12-22 20:44:03 Epoch: 12 train-Loss: 0.1876 train-Acc: 0.9368, Cost 0.2777 sec
12-22 20:44:03 Epoch: 12 val-Loss: 0.0296 val-Acc: 0.9885, Cost 0.0440 sec
12-22 20:44:03 -----Epoch 13/99-----
12-22 20:44:03 current lr: 0.001
12-22 20:44:03 Epoch: 13 train-Loss: 0.2086 train-Acc: 0.9301, Cost 0.2627 sec
12-22 20:44:03 Epoch: 13 val-Loss: 0.0239 val-Acc: 0.9885, Cost 0.0310 sec
12-22 20:44:03 -----Epoch 14/99-----
12-22 20:44:03 current lr: 0.001
12-22 20:44:04 Epoch: 14 train-Loss: 0.1491 train-Acc: 0.9531, Cost 0.2757 sec
12-22 20:44:04 Epoch: 14 val-Loss: 0.0487 val-Acc: 0.9923, Cost 0.0320 sec
12-22 20:44:04 -----Epoch 15/99-----
12-22 20:44:04 current lr: 0.001
12-22 20:44:04 Epoch: 15 train-Loss: 0.1846 train-Acc: 0.9339, Cost 0.2597 sec
12-22 20:44:04 Epoch: 15 val-Loss: 0.0163 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:04 save best model epoch 15, acc 1.0000
12-22 20:44:04 -----Epoch 16/99-----
12-22 20:44:04 current lr: 0.001
12-22 20:44:04 Epoch: 16 train-Loss: 0.2121 train-Acc: 0.9406, Cost 0.2627 sec
12-22 20:44:04 Epoch: 16 val-Loss: 0.0099 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:04 -----Epoch 17/99-----
12-22 20:44:04 current lr: 0.001
12-22 20:44:05 Epoch: 17 [704/1044], Train Loss: 0.1802 Train Acc: 0.9404,3425.8 examples/sec 0.02 sec/batch
12-22 20:44:05 Epoch: 17 train-Loss: 0.1012 train-Acc: 0.9636, Cost 0.2567 sec
12-22 20:44:05 Epoch: 17 val-Loss: 0.0205 val-Acc: 0.9923, Cost 0.0320 sec
12-22 20:44:05 -----Epoch 18/99-----
12-22 20:44:05 current lr: 0.001
12-22 20:44:05 Epoch: 18 train-Loss: 0.1516 train-Acc: 0.9454, Cost 0.2587 sec
12-22 20:44:05 Epoch: 18 val-Loss: 0.0087 val-Acc: 0.9962, Cost 0.0320 sec
12-22 20:44:05 -----Epoch 19/99-----
12-22 20:44:05 current lr: 0.001
12-22 20:44:05 Epoch: 19 train-Loss: 0.1058 train-Acc: 0.9646, Cost 0.2577 sec
12-22 20:44:05 Epoch: 19 val-Loss: 0.0078 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:05 -----Epoch 20/99-----
12-22 20:44:05 current lr: 0.001
12-22 20:44:06 Epoch: 20 train-Loss: 0.0986 train-Acc: 0.9665, Cost 0.2597 sec
12-22 20:44:06 Epoch: 20 val-Loss: 0.0087 val-Acc: 0.9962, Cost 0.0320 sec
12-22 20:44:06 -----Epoch 21/99-----
12-22 20:44:06 current lr: 0.001
12-22 20:44:06 Epoch: 21 train-Loss: 0.1326 train-Acc: 0.9559, Cost 0.2557 sec
12-22 20:44:06 Epoch: 21 val-Loss: 0.0046 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:06 -----Epoch 22/99-----
12-22 20:44:06 current lr: 0.001
12-22 20:44:06 Epoch: 22 train-Loss: 0.0884 train-Acc: 0.9684, Cost 0.2587 sec
12-22 20:44:06 Epoch: 22 val-Loss: 0.0023 val-Acc: 1.0000, Cost 0.0340 sec
12-22 20:44:06 -----Epoch 23/99-----
12-22 20:44:06 current lr: 0.001
12-22 20:44:06 Epoch: 23 [576/1044], Train Loss: 0.1109 Train Acc: 0.9615,3571.2 examples/sec 0.02 sec/batch
12-22 20:44:06 Epoch: 23 train-Loss: 0.0990 train-Acc: 0.9626, Cost 0.2637 sec
12-22 20:44:06 Epoch: 23 val-Loss: 0.0023 val-Acc: 1.0000, Cost 0.0340 sec
12-22 20:44:06 -----Epoch 24/99-----
12-22 20:44:06 current lr: 0.001
12-22 20:44:07 Epoch: 24 train-Loss: 0.1366 train-Acc: 0.9559, Cost 0.2587 sec
12-22 20:44:07 Epoch: 24 val-Loss: 0.0136 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:07 -----Epoch 25/99-----
12-22 20:44:07 current lr: 0.001
12-22 20:44:07 Epoch: 25 train-Loss: 0.1213 train-Acc: 0.9626, Cost 0.2597 sec
12-22 20:44:07 Epoch: 25 val-Loss: 0.0041 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:07 -----Epoch 26/99-----
12-22 20:44:07 current lr: 0.001
12-22 20:44:07 Epoch: 26 train-Loss: 0.0865 train-Acc: 0.9722, Cost 0.2737 sec
12-22 20:44:07 Epoch: 26 val-Loss: 0.0060 val-Acc: 0.9962, Cost 0.0320 sec
12-22 20:44:07 -----Epoch 27/99-----
12-22 20:44:07 current lr: 0.001
12-22 20:44:08 Epoch: 27 train-Loss: 0.1116 train-Acc: 0.9684, Cost 0.2637 sec
12-22 20:44:08 Epoch: 27 val-Loss: 0.0026 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:08 -----Epoch 28/99-----
12-22 20:44:08 current lr: 0.001
12-22 20:44:08 Epoch: 28 train-Loss: 0.0957 train-Acc: 0.9674, Cost 0.2587 sec
12-22 20:44:08 Epoch: 28 val-Loss: 0.0012 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:08 -----Epoch 29/99-----
12-22 20:44:08 current lr: 0.001
12-22 20:44:08 Epoch: 29 [448/1044], Train Loss: 0.1085 Train Acc: 0.9654,3518.0 examples/sec 0.02 sec/batch
12-22 20:44:08 Epoch: 29 train-Loss: 0.0821 train-Acc: 0.9761, Cost 0.2567 sec
12-22 20:44:08 Epoch: 29 val-Loss: 0.0008 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:08 -----Epoch 30/99-----
12-22 20:44:08 current lr: 0.001
12-22 20:44:08 Epoch: 30 train-Loss: 0.1235 train-Acc: 0.9665, Cost 0.2667 sec
12-22 20:44:09 Epoch: 30 val-Loss: 0.0224 val-Acc: 0.9885, Cost 0.0320 sec
12-22 20:44:09 -----Epoch 31/99-----
12-22 20:44:09 current lr: 0.001
12-22 20:44:09 Epoch: 31 train-Loss: 0.0963 train-Acc: 0.9703, Cost 0.2577 sec
12-22 20:44:09 Epoch: 31 val-Loss: 0.0013 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:09 -----Epoch 32/99-----
12-22 20:44:09 current lr: 0.001
12-22 20:44:09 Epoch: 32 train-Loss: 0.0730 train-Acc: 0.9761, Cost 0.2567 sec
12-22 20:44:09 Epoch: 32 val-Loss: 0.0032 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:09 -----Epoch 33/99-----
12-22 20:44:09 current lr: 0.001
12-22 20:44:09 Epoch: 33 train-Loss: 0.0846 train-Acc: 0.9665, Cost 0.2567 sec
12-22 20:44:09 Epoch: 33 val-Loss: 0.0014 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:09 -----Epoch 34/99-----
12-22 20:44:09 current lr: 0.001
12-22 20:44:10 Epoch: 34 train-Loss: 0.0754 train-Acc: 0.9732, Cost 0.2597 sec
12-22 20:44:10 Epoch: 34 val-Loss: 0.0009 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:10 -----Epoch 35/99-----
12-22 20:44:10 current lr: 0.001
12-22 20:44:10 Epoch: 35 [320/1044], Train Loss: 0.0901 Train Acc: 0.9716,3565.0 examples/sec 0.02 sec/batch
12-22 20:44:10 Epoch: 35 train-Loss: 0.0715 train-Acc: 0.9808, Cost 0.2617 sec
12-22 20:44:10 Epoch: 35 val-Loss: 0.0035 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:10 -----Epoch 36/99-----
12-22 20:44:10 current lr: 0.001
12-22 20:44:10 Epoch: 36 train-Loss: 0.0458 train-Acc: 0.9818, Cost 0.2487 sec
12-22 20:44:10 Epoch: 36 val-Loss: 0.0003 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:10 -----Epoch 37/99-----
12-22 20:44:10 current lr: 0.001
12-22 20:44:11 Epoch: 37 train-Loss: 0.0573 train-Acc: 0.9828, Cost 0.2637 sec
12-22 20:44:11 Epoch: 37 val-Loss: 0.0004 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:11 -----Epoch 38/99-----
12-22 20:44:11 current lr: 0.001
12-22 20:44:11 Epoch: 38 train-Loss: 0.0723 train-Acc: 0.9770, Cost 0.2627 sec
12-22 20:44:11 Epoch: 38 val-Loss: 0.0041 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:11 -----Epoch 39/99-----
12-22 20:44:11 current lr: 0.001
12-22 20:44:11 Epoch: 39 train-Loss: 0.0856 train-Acc: 0.9770, Cost 0.2527 sec
12-22 20:44:11 Epoch: 39 val-Loss: 0.0013 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:11 -----Epoch 40/99-----
12-22 20:44:11 current lr: 0.001
12-22 20:44:11 Epoch: 40 train-Loss: 0.0969 train-Acc: 0.9722, Cost 0.2607 sec
12-22 20:44:11 Epoch: 40 val-Loss: 0.0053 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:11 -----Epoch 41/99-----
12-22 20:44:11 current lr: 0.001
12-22 20:44:11 Epoch: 41 [192/1044], Train Loss: 0.0724 Train Acc: 0.9773,3571.2 examples/sec 0.02 sec/batch
12-22 20:44:12 Epoch: 41 train-Loss: 0.0751 train-Acc: 0.9770, Cost 0.2637 sec
12-22 20:44:12 Epoch: 41 val-Loss: 0.0009 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:12 -----Epoch 42/99-----
12-22 20:44:12 current lr: 0.001
12-22 20:44:12 Epoch: 42 train-Loss: 0.0694 train-Acc: 0.9789, Cost 0.2507 sec
12-22 20:44:12 Epoch: 42 val-Loss: 0.0016 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:12 -----Epoch 43/99-----
12-22 20:44:12 current lr: 0.001
12-22 20:44:12 Epoch: 43 train-Loss: 0.0534 train-Acc: 0.9856, Cost 0.2607 sec
12-22 20:44:12 Epoch: 43 val-Loss: 0.0468 val-Acc: 0.9847, Cost 0.0330 sec
12-22 20:44:12 -----Epoch 44/99-----
12-22 20:44:12 current lr: 0.001
12-22 20:44:13 Epoch: 44 train-Loss: 0.1159 train-Acc: 0.9674, Cost 0.2597 sec
12-22 20:44:13 Epoch: 44 val-Loss: 0.0012 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:13 -----Epoch 45/99-----
12-22 20:44:13 current lr: 0.001
12-22 20:44:13 Epoch: 45 train-Loss: 0.0450 train-Acc: 0.9818, Cost 0.2647 sec
12-22 20:44:13 Epoch: 45 val-Loss: 0.0007 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:13 -----Epoch 46/99-----
12-22 20:44:13 current lr: 0.001
12-22 20:44:13 Epoch: 46 train-Loss: 0.0513 train-Acc: 0.9799, Cost 0.2587 sec
12-22 20:44:13 Epoch: 46 val-Loss: 0.0013 val-Acc: 1.0000, Cost 0.0350 sec
12-22 20:44:13 -----Epoch 47/99-----
12-22 20:44:13 current lr: 0.001
12-22 20:44:13 Epoch: 47 [64/1044], Train Loss: 0.0660 Train Acc: 0.9798,3550.6 examples/sec 0.02 sec/batch
12-22 20:44:13 Epoch: 47 train-Loss: 0.0535 train-Acc: 0.9866, Cost 0.2587 sec
12-22 20:44:13 Epoch: 47 val-Loss: 0.0050 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:13 -----Epoch 48/99-----
12-22 20:44:13 current lr: 0.001
12-22 20:44:14 Epoch: 48 train-Loss: 0.0579 train-Acc: 0.9780, Cost 0.2587 sec
12-22 20:44:14 Epoch: 48 val-Loss: 0.0006 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:14 -----Epoch 49/99-----
12-22 20:44:14 current lr: 0.001
12-22 20:44:14 Epoch: 49 train-Loss: 0.0761 train-Acc: 0.9780, Cost 0.2597 sec
12-22 20:44:14 Epoch: 49 val-Loss: 0.0013 val-Acc: 1.0000, Cost 0.0310 sec
12-22 20:44:14 -----Epoch 50/99-----
12-22 20:44:14 current lr: 0.001
12-22 20:44:14 Epoch: 50 train-Loss: 0.0521 train-Acc: 0.9818, Cost 0.2607 sec
12-22 20:44:14 Epoch: 50 val-Loss: 0.0004 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:14 -----Epoch 51/99-----
12-22 20:44:14 current lr: 0.001
12-22 20:44:15 Epoch: 51 train-Loss: 0.0765 train-Acc: 0.9818, Cost 0.2597 sec
12-22 20:44:15 Epoch: 51 val-Loss: 0.0095 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:15 -----Epoch 52/99-----
12-22 20:44:15 current lr: 0.001
12-22 20:44:15 Epoch: 52 [320/1044], Train Loss: 0.0709 Train Acc: 0.9788,3630.3 examples/sec 0.02 sec/batch
12-22 20:44:15 Epoch: 52 train-Loss: 0.1056 train-Acc: 0.9684, Cost 0.2627 sec
12-22 20:44:15 Epoch: 52 val-Loss: 0.0030 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:15 -----Epoch 53/99-----
12-22 20:44:15 current lr: 0.001
12-22 20:44:15 Epoch: 53 train-Loss: 0.0413 train-Acc: 0.9885, Cost 0.2587 sec
12-22 20:44:15 Epoch: 53 val-Loss: 0.0037 val-Acc: 1.0000, Cost 0.0340 sec
12-22 20:44:15 -----Epoch 54/99-----
12-22 20:44:15 current lr: 0.001
12-22 20:44:15 Epoch: 54 train-Loss: 0.0524 train-Acc: 0.9818, Cost 0.2577 sec
12-22 20:44:16 Epoch: 54 val-Loss: 0.0006 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:16 -----Epoch 55/99-----
12-22 20:44:16 current lr: 0.001
12-22 20:44:16 Epoch: 55 train-Loss: 0.0521 train-Acc: 0.9847, Cost 0.2617 sec
12-22 20:44:16 Epoch: 55 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:16 -----Epoch 56/99-----
12-22 20:44:16 current lr: 0.001
12-22 20:44:16 Epoch: 56 train-Loss: 0.0645 train-Acc: 0.9770, Cost 0.2567 sec
12-22 20:44:16 Epoch: 56 val-Loss: 0.0004 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:16 -----Epoch 57/99-----
12-22 20:44:16 current lr: 0.001
12-22 20:44:16 Epoch: 57 train-Loss: 0.0281 train-Acc: 0.9904, Cost 0.2607 sec
12-22 20:44:16 Epoch: 57 val-Loss: 0.0001 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:16 -----Epoch 58/99-----
12-22 20:44:16 current lr: 0.001
12-22 20:44:17 Epoch: 58 [896/1044], Train Loss: 0.0484 Train Acc: 0.9850,3580.2 examples/sec 0.02 sec/batch
12-22 20:44:17 Epoch: 58 train-Loss: 0.0520 train-Acc: 0.9875, Cost 0.2557 sec
12-22 20:44:17 Epoch: 58 val-Loss: 0.0007 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:17 -----Epoch 59/99-----
12-22 20:44:17 current lr: 0.001
12-22 20:44:17 Epoch: 59 train-Loss: 0.0624 train-Acc: 0.9799, Cost 0.2597 sec
12-22 20:44:17 Epoch: 59 val-Loss: 0.0006 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:17 -----Epoch 60/99-----
12-22 20:44:17 current lr: 0.001
12-22 20:44:17 Epoch: 60 train-Loss: 0.0560 train-Acc: 0.9847, Cost 0.2587 sec
12-22 20:44:17 Epoch: 60 val-Loss: 0.0008 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:17 -----Epoch 61/99-----
12-22 20:44:17 current lr: 0.001
12-22 20:44:18 Epoch: 61 train-Loss: 0.0633 train-Acc: 0.9770, Cost 0.2587 sec
12-22 20:44:18 Epoch: 61 val-Loss: 0.0008 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:18 -----Epoch 62/99-----
12-22 20:44:18 current lr: 0.001
12-22 20:44:18 Epoch: 62 train-Loss: 0.0415 train-Acc: 0.9895, Cost 0.2607 sec
12-22 20:44:18 Epoch: 62 val-Loss: 0.0019 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:18 -----Epoch 63/99-----
12-22 20:44:18 current lr: 0.001
12-22 20:44:18 Epoch: 63 train-Loss: 0.0281 train-Acc: 0.9875, Cost 0.2567 sec
12-22 20:44:18 Epoch: 63 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:18 -----Epoch 64/99-----
12-22 20:44:18 current lr: 0.001
12-22 20:44:18 Epoch: 64 [768/1044], Train Loss: 0.0512 Train Acc: 0.9837,3538.3 examples/sec 0.02 sec/batch
12-22 20:44:18 Epoch: 64 train-Loss: 0.0505 train-Acc: 0.9856, Cost 0.2807 sec
12-22 20:44:18 Epoch: 64 val-Loss: 0.0004 val-Acc: 1.0000, Cost 0.0310 sec
12-22 20:44:18 -----Epoch 65/99-----
12-22 20:44:18 current lr: 0.001
12-22 20:44:19 Epoch: 65 train-Loss: 0.0530 train-Acc: 0.9847, Cost 0.2757 sec
12-22 20:44:19 Epoch: 65 val-Loss: 0.0020 val-Acc: 1.0000, Cost 0.0310 sec
12-22 20:44:19 -----Epoch 66/99-----
12-22 20:44:19 current lr: 0.001
12-22 20:44:19 Epoch: 66 train-Loss: 0.0424 train-Acc: 0.9866, Cost 0.2607 sec
12-22 20:44:19 Epoch: 66 val-Loss: 0.0004 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:19 -----Epoch 67/99-----
12-22 20:44:19 current lr: 0.001
12-22 20:44:19 Epoch: 67 train-Loss: 0.0403 train-Acc: 0.9866, Cost 0.2567 sec
12-22 20:44:19 Epoch: 67 val-Loss: 0.0079 val-Acc: 0.9962, Cost 0.0460 sec
12-22 20:44:19 -----Epoch 68/99-----
12-22 20:44:19 current lr: 0.001
12-22 20:44:20 Epoch: 68 train-Loss: 0.0560 train-Acc: 0.9799, Cost 0.2557 sec
12-22 20:44:20 Epoch: 68 val-Loss: 0.0035 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:20 -----Epoch 69/99-----
12-22 20:44:20 current lr: 0.001
12-22 20:44:20 Epoch: 69 train-Loss: 0.0764 train-Acc: 0.9751, Cost 0.2637 sec
12-22 20:44:20 Epoch: 69 val-Loss: 0.0037 val-Acc: 1.0000, Cost 0.0310 sec
12-22 20:44:20 -----Epoch 70/99-----
12-22 20:44:20 current lr: 0.001
12-22 20:44:20 Epoch: 70 [640/1044], Train Loss: 0.0561 Train Acc: 0.9814,3502.0 examples/sec 0.02 sec/batch
12-22 20:44:20 Epoch: 70 train-Loss: 0.0768 train-Acc: 0.9713, Cost 0.2587 sec
12-22 20:44:20 Epoch: 70 val-Loss: 0.0012 val-Acc: 1.0000, Cost 0.0509 sec
12-22 20:44:20 -----Epoch 71/99-----
12-22 20:44:20 current lr: 0.001
12-22 20:44:21 Epoch: 71 train-Loss: 0.0433 train-Acc: 0.9943, Cost 0.2597 sec
12-22 20:44:21 Epoch: 71 val-Loss: 0.0008 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:21 -----Epoch 72/99-----
12-22 20:44:21 current lr: 0.001
12-22 20:44:21 Epoch: 72 train-Loss: 0.0228 train-Acc: 0.9943, Cost 0.2597 sec
12-22 20:44:21 Epoch: 72 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0470 sec
12-22 20:44:21 -----Epoch 73/99-----
12-22 20:44:21 current lr: 0.001
12-22 20:44:21 Epoch: 73 train-Loss: 0.0391 train-Acc: 0.9847, Cost 0.2517 sec
12-22 20:44:21 Epoch: 73 val-Loss: 0.0053 val-Acc: 0.9962, Cost 0.0310 sec
12-22 20:44:21 -----Epoch 74/99-----
12-22 20:44:21 current lr: 0.001
12-22 20:44:21 Epoch: 74 train-Loss: 0.0549 train-Acc: 0.9808, Cost 0.2637 sec
12-22 20:44:21 Epoch: 74 val-Loss: 0.0005 val-Acc: 1.0000, Cost 0.0340 sec
12-22 20:44:21 -----Epoch 75/99-----
12-22 20:44:21 current lr: 0.001
12-22 20:44:22 Epoch: 75 train-Loss: 0.0350 train-Acc: 0.9866, Cost 0.2687 sec
12-22 20:44:22 Epoch: 75 val-Loss: 0.0005 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:22 -----Epoch 76/99-----
12-22 20:44:22 current lr: 0.001
12-22 20:44:22 Epoch: 76 [512/1044], Train Loss: 0.0399 Train Acc: 0.9876,3478.2 examples/sec 0.02 sec/batch
12-22 20:44:22 Epoch: 76 train-Loss: 0.0401 train-Acc: 0.9875, Cost 0.2547 sec
12-22 20:44:22 Epoch: 76 val-Loss: 0.0007 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:22 -----Epoch 77/99-----
12-22 20:44:22 current lr: 0.001
12-22 20:44:22 Epoch: 77 train-Loss: 0.0267 train-Acc: 0.9914, Cost 0.2627 sec
12-22 20:44:22 Epoch: 77 val-Loss: 0.0001 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:22 -----Epoch 78/99-----
12-22 20:44:22 current lr: 0.001
12-22 20:44:23 Epoch: 78 train-Loss: 0.0274 train-Acc: 0.9904, Cost 0.2647 sec
12-22 20:44:23 Epoch: 78 val-Loss: 0.0048 val-Acc: 0.9962, Cost 0.0320 sec
12-22 20:44:23 -----Epoch 79/99-----
12-22 20:44:23 current lr: 0.001
12-22 20:44:23 Epoch: 79 train-Loss: 0.0351 train-Acc: 0.9914, Cost 0.2687 sec
12-22 20:44:23 Epoch: 79 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:23 -----Epoch 80/99-----
12-22 20:44:23 current lr: 0.001
12-22 20:44:23 Epoch: 80 train-Loss: 0.0267 train-Acc: 0.9943, Cost 0.2657 sec
12-22 20:44:23 Epoch: 80 val-Loss: 0.0003 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:23 -----Epoch 81/99-----
12-22 20:44:23 current lr: 0.001
12-22 20:44:23 Epoch: 81 train-Loss: 0.0486 train-Acc: 0.9856, Cost 0.2637 sec
12-22 20:44:24 Epoch: 81 val-Loss: 0.0003 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:24 -----Epoch 82/99-----
12-22 20:44:24 current lr: 0.001
12-22 20:44:24 Epoch: 82 [384/1044], Train Loss: 0.0332 Train Acc: 0.9902,3504.0 examples/sec 0.02 sec/batch
12-22 20:44:24 Epoch: 82 train-Loss: 0.0248 train-Acc: 0.9914, Cost 0.2617 sec
12-22 20:44:24 Epoch: 82 val-Loss: 0.0016 val-Acc: 1.0000, Cost 0.0310 sec
12-22 20:44:24 -----Epoch 83/99-----
12-22 20:44:24 current lr: 0.001
12-22 20:44:24 Epoch: 83 train-Loss: 0.0290 train-Acc: 0.9933, Cost 0.2547 sec
12-22 20:44:24 Epoch: 83 val-Loss: 0.0001 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:24 -----Epoch 84/99-----
12-22 20:44:24 current lr: 0.001
12-22 20:44:24 Epoch: 84 train-Loss: 0.0396 train-Acc: 0.9885, Cost 0.2577 sec
12-22 20:44:24 Epoch: 84 val-Loss: 0.0006 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:24 -----Epoch 85/99-----
12-22 20:44:24 current lr: 0.001
12-22 20:44:25 Epoch: 85 train-Loss: 0.0145 train-Acc: 0.9952, Cost 0.2587 sec
12-22 20:44:25 Epoch: 85 val-Loss: 0.0009 val-Acc: 1.0000, Cost 0.0420 sec
12-22 20:44:25 -----Epoch 86/99-----
12-22 20:44:25 current lr: 0.001
12-22 20:44:25 Epoch: 86 train-Loss: 0.0220 train-Acc: 0.9923, Cost 0.2627 sec
12-22 20:44:25 Epoch: 86 val-Loss: 0.0005 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:25 -----Epoch 87/99-----
12-22 20:44:25 current lr: 0.001
12-22 20:44:25 Epoch: 87 train-Loss: 0.0421 train-Acc: 0.9875, Cost 0.2537 sec
12-22 20:44:25 Epoch: 87 val-Loss: 0.0028 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:25 -----Epoch 88/99-----
12-22 20:44:25 current lr: 0.001
12-22 20:44:25 Epoch: 88 [256/1044], Train Loss: 0.0304 Train Acc: 0.9910,3558.8 examples/sec 0.02 sec/batch
12-22 20:44:26 Epoch: 88 train-Loss: 0.0371 train-Acc: 0.9885, Cost 0.2637 sec
12-22 20:44:26 Epoch: 88 val-Loss: 0.0027 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:26 -----Epoch 89/99-----
12-22 20:44:26 current lr: 0.001
12-22 20:44:26 Epoch: 89 train-Loss: 0.0488 train-Acc: 0.9856, Cost 0.2607 sec
12-22 20:44:26 Epoch: 89 val-Loss: 0.0019 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:26 -----Epoch 90/99-----
12-22 20:44:26 current lr: 0.001
12-22 20:44:26 Epoch: 90 train-Loss: 0.0277 train-Acc: 0.9875, Cost 0.2547 sec
12-22 20:44:26 Epoch: 90 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:26 -----Epoch 91/99-----
12-22 20:44:26 current lr: 0.001
12-22 20:44:26 Epoch: 91 train-Loss: 0.0272 train-Acc: 0.9904, Cost 0.2587 sec
12-22 20:44:26 Epoch: 91 val-Loss: 0.0006 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:26 -----Epoch 92/99-----
12-22 20:44:26 current lr: 0.001
12-22 20:44:27 Epoch: 92 train-Loss: 0.0167 train-Acc: 0.9904, Cost 0.2577 sec
12-22 20:44:27 Epoch: 92 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:27 -----Epoch 93/99-----
12-22 20:44:27 current lr: 0.001
12-22 20:44:27 Epoch: 93 train-Loss: 0.0432 train-Acc: 0.9856, Cost 0.2657 sec
12-22 20:44:27 Epoch: 93 val-Loss: 0.0004 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:27 -----Epoch 94/99-----
12-22 20:44:27 current lr: 0.001
12-22 20:44:27 Epoch: 94 [128/1044], Train Loss: 0.0321 Train Acc: 0.9884,3560.9 examples/sec 0.02 sec/batch
12-22 20:44:27 Epoch: 94 train-Loss: 0.0547 train-Acc: 0.9808, Cost 0.2557 sec
12-22 20:44:27 Epoch: 94 val-Loss: 0.0018 val-Acc: 1.0000, Cost 0.0330 sec
12-22 20:44:27 -----Epoch 95/99-----
12-22 20:44:27 current lr: 0.001
12-22 20:44:28 Epoch: 95 train-Loss: 0.0476 train-Acc: 0.9789, Cost 0.2567 sec
12-22 20:44:28 Epoch: 95 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:28 -----Epoch 96/99-----
12-22 20:44:28 current lr: 0.001
12-22 20:44:28 Epoch: 96 train-Loss: 0.0498 train-Acc: 0.9866, Cost 0.2607 sec
12-22 20:44:28 Epoch: 96 val-Loss: 0.0001 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:28 -----Epoch 97/99-----
12-22 20:44:28 current lr: 0.001
12-22 20:44:28 Epoch: 97 train-Loss: 0.0237 train-Acc: 0.9914, Cost 0.2627 sec
12-22 20:44:28 Epoch: 97 val-Loss: 0.0002 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:28 -----Epoch 98/99-----
12-22 20:44:28 current lr: 0.001
12-22 20:44:28 Epoch: 98 train-Loss: 0.0348 train-Acc: 0.9885, Cost 0.2627 sec
12-22 20:44:29 Epoch: 98 val-Loss: 0.0072 val-Acc: 0.9962, Cost 0.0320 sec
12-22 20:44:29 -----Epoch 99/99-----
12-22 20:44:29 current lr: 0.001
12-22 20:44:29 Epoch: 99 train-Loss: 0.0497 train-Acc: 0.9856, Cost 0.2547 sec
12-22 20:44:29 Epoch: 99 val-Loss: 0.0015 val-Acc: 1.0000, Cost 0.0320 sec
12-22 20:44:29 save best model epoch 99, acc 1.0000
